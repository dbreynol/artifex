<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Regression basics</title>

<script src="site_libs/header-attrs-2.6/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Artifex Spring 2022</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="regression.html">Regression</a>
</li>
<li>
  <a href="Rintro.html">Toolbox - R</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Regression basics</h1>

</div>


<div id="fundamentals-of-linear-regression---inference" class="section level3">
<h3>2. Fundamentals of Linear Regression - Inference</h3>
<p>Last time, we discussed a few ways to estimate the slope coefficient in a linear regression model. This yields a point estimate. The other key ingredient for inference is to determine how much uncertainty there is in our estimate. For the case of <span class="math inline">\(\hat{\beta_1}\)</span>, we want to know how much this estimate varies from sample to sample for the specified sample size. That is, we want to know the variance of the estimate:</p>
<p><span class="math display">\[\begin{align}
Var(\hat{\beta_1}).
\end{align}\]</span></p>
<p>To find what this is, let’s just try to figure out the variance directly, using the analytic formula for <span class="math inline">\(\hat{\beta_1}\)</span> in simple linear regression:</p>
<p><span class="math display">\[\begin{align}
Var \bigg( \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2 }  \bigg).
\end{align}\]</span></p>
<p>To carry out this calculation, recall that <span class="math inline">\(\text{var}(cx) = c^2 \text{var}(x)\)</span>. Also, recall the model assumption of independence across observations. After carrying out this calculation, we can show that,</p>
<p><span class="math display">\[\begin{equation}
Var(\hat{\beta}) = \frac{\hat{\sigma}^2}{(n-1) \hat{var}(x)}
\end{equation}\]</span></p>
<p>How does variation in <span class="math inline">\(\hat{\beta}\)</span> respond to changes in sample size? How about to variation in the predictor?</p>
<p>Before moving on, let’s write some code to make sure our calculations correspond with those generated by <code>lm</code>.</p>
<pre class="r"><code>set.seed(1)
n = 1000 # number of observations
X = rnorm(n) # predictor
beta_0 = 2 # intercept
beta_1 = 3 # slope
y = rnorm(n , mean = beta_0 + beta_1 * X, sd = 1 )

mod = lm(y ~ X)

pander(summary(mod))</code></pre>
<table style="width:88%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">1.984</td>
<td align="center">0.0329</td>
<td align="center">60.29</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>X</strong></td>
<td align="center">3.006</td>
<td align="center">0.03181</td>
<td align="center">94.52</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<table style="width:88%;">
<caption>Fitting linear model: y ~ X</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="12%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1000</td>
<td align="center">1.04</td>
<td align="center">0.8995</td>
<td align="center">0.8994</td>
</tr>
</tbody>
</table>
<pre class="r"><code>sig.sq = sum(mod$residuals^2)/df.residual(mod) # sigma squared est
sqrt(sig.sq/ (var(X) * (n-1) ) )</code></pre>
<pre><code>## [1] 0.03180874</code></pre>
<p>In this case, we are able to obtain not only the variation of the estimate but also the distribution of the estimate as well as the test statistic,</p>
<p><span class="math display">\[\begin{align}
T = \frac{\hat{\beta_1} - \beta}{\sqrt{\text{var}\beta}} \sim t_{n-2}
\end{align}\]</span></p>
<p>This allows us to compute confidence intervals. For instance, if we want to compute a (1-<span class="math inline">\(\alpha\)</span>) confidence interval, note that:</p>
<p><span class="math display">\[\begin{align}
P(t_{\alpha/2} &lt; T &lt; t_{1-\alpha/2}) = (1-\alpha)
\end{align}\]</span></p>
<div id="bootstrap" class="section level4">
<h4>Bootstrap</h4>
<p>In more realistic scenarios, we may not be able to obtain analytic results for the variance of an estimator. Fortunately, there are some workarounds. One such method is the bootstrap. The bootstrap is incredibly simple and effective. Let’s denote our sample as <span class="math inline">\(\mathbf{X} = (X_1,\ldots,X_n)\)</span> and the statistic as <span class="math inline">\(T(\mathbf{X})\)</span>. The algorithm consists two key steps. For <span class="math inline">\(i \in 1,\ldots,n\)</span>:</p>
<ol style="list-style-type: decimal">
<li>Resample the original data (with replacement). This results in a <em>new</em> dataset, <span class="math inline">\(\mathbf{X^\star}\)</span>, that is the same size as the original data.</li>
<li>Compute the desired statistic on the resampled data. This results in a number, <span class="math inline">\(s_i = T(\mathbf{X}^\star)\)</span></li>
</ol>
<p>This results in a sample of statistics <span class="math inline">\(\mathbf{s}=(s_1, \ldots,s_B)\)</span>. We can then estimate the variance of the statistic as the sample variance: <span class="math inline">\(\text{var}(\mathbf{s})\)</span>.</p>
<p>Let’s first do a simple example before returning to linear regression. Suppose we would like to estimate the variance of the sample mean. Let’s write a bootstrap algorithm to do this.</p>
<pre class="r"><code># first, let&#39;s sample some data
set.seed(2)
orig.sample = rexp(1000, rate = 2)

B = 1e4
means = rep(0, B)
for(i in 1:B) {
  newdat.inds = sample(1000, 1000, replace = T)
  newdat = orig.sample[newdat.inds]
  means[i] = mean(newdat)
}

print(c(mean(means), sd(means)))</code></pre>
<pre><code>## [1] 0.51801949 0.01611761</code></pre>
<p>Now, back to regression. Let’s use the same framework to estimate the variance of the slope coefficient.</p>
<pre class="r"><code>nIter = 10000
beta.vec = array(NA, dim = c(nIter, 2))

for(i in 1:nIter) {
  inds = sample(n, n, replace = T)
  y.t = y[inds]
  X.t = X[inds]
  m = lm(y.t ~ X.t)
  beta.vec[i, ] = coefficients(m)
}


print(sd(beta.vec[,2]))</code></pre>
<pre><code>## [1] 0.03310038</code></pre>
</div>
<div id="exercises-3" class="section level4">
<h4>Exercises 3</h4>
<ol style="list-style-type: decimal">
<li>Run the code below to simulate data from a <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a>. Generate a histogram and describe it (where is the mode? what is the skew?)</li>
</ol>
<pre class="r"><code>set.seed(2)
ns = 1000
gam.sample = rgamma(ns, shape = 1, rate = 2) # alpha = 1, beta = 2</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>What is the relationship between the sample mean and median? What do you think is the relationship in the variability in these two sample statistics (i.e., if we were to draw another sample from this distribution, which one would change more on average)?</p></li>
<li><p>Using the bootstrap, generate a bootstrap sample of sample means (try to use the code above as little as possible). Use <span class="math inline">\(B = 10^4\)</span>. What is the mean and standard deviation of this sample?</p></li>
<li><p>Using the bootstrap, generate a bootstrap sample of sample medians (try to use the code above as little as possible). Use <span class="math inline">\(B = 10^4\)</span>. What is the mean and standard deviation of this sample?</p></li>
<li><p>Plot histograms of both bootstrap samples on one graphic. <a href="https://stackoverflow.com/questions/3541713/how-to-plot-two-histograms-together-in-r">See hints on this page</a></p></li>
<li><p>Going back to the hypothesis you tested in exercise 1 (question 2), estimate the standard deviation of the slope coefficient using bootstrap. How does it compare with the output generated by <code>lm</code>.</p></li>
</ol>
</div>
</div>
<div id="fundamentals-of-linear-regression---estimation" class="section level3">
<h3>1. Fundamentals of Linear Regression - Estimation</h3>
<div id="introduction" class="section level4">
<h4>Introduction</h4>
<p>Suppose we want to model a response variable <span class="math inline">\(Y\)</span> in terms of some predictor variables, <span class="math inline">\((X_1, X_2, X_3)\)</span>. One very general form of the model would be:</p>
<p><span class="math display">\[\begin{equation}
Y = f(X_1, X_2, X_3) + \epsilon
\end{equation}\]</span></p>
<p>where <span class="math inline">\(f\)</span> is some unknown function and <span class="math inline">\(\epsilon\)</span> is the error. Usually the exact function <span class="math inline">\(f\)</span> is unknown and we have to make assumptions about it. One such assumption is that <span class="math inline">\(f\)</span> is a linear function, which implies the following model:</p>
<p><span class="math display">\[\begin{equation}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2+ \beta_3 X_3 + \epsilon.
\end{equation}\]</span></p>
<p>In this model, <span class="math inline">\((\beta_0, \beta_1, \beta_2, \beta_3)\)</span> are unknown parameters. Thus, the <em>estimation</em> problem involves trying to estimate this set of coefficients.</p>
<p>Although this model may seem restrictive and simple, it is an extremely useful tool for gathering insight about data. It also introduces fundamental concepts to more complex statistical/ machine learning methods.</p>
</div>
<div id="example" class="section level4">
<h4>Example</h4>
<p>Let’s do a simple example regression analysis. We will use the county dataset from the openintro package to assess the linear association between the proportion of high school graduates in a country and the proportion of the county living in poverty.</p>
<pre class="r"><code># this chunk requires tidyverse and kableextra packages
dat = county_complete %&gt;% select(hs_grad_2019, poverty_2019) # select response, predictor
kable(head(dat)) %&gt;%
  kable_styling(position = &quot;center&quot;) # kable prints a dataframe </code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
hs_grad_2019
</th>
<th style="text-align:right;">
poverty_2019
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
88.5
</td>
<td style="text-align:right;">
15.2
</td>
</tr>
<tr>
<td style="text-align:right;">
90.8
</td>
<td style="text-align:right;">
10.4
</td>
</tr>
<tr>
<td style="text-align:right;">
73.2
</td>
<td style="text-align:right;">
30.7
</td>
</tr>
<tr>
<td style="text-align:right;">
79.1
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:right;">
80.5
</td>
<td style="text-align:right;">
13.6
</td>
</tr>
<tr>
<td style="text-align:right;">
74.7
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>A good first step to any analysis is to visually explore the data. For this particular case, it is hard to beat a scatterplot for visualization.</p>
<pre class="r"><code>ggplot(dat, aes(x= hs_grad_2019, y = poverty_2019)) + 
  geom_point(alpha = 0.5) + 
  theme_minimal() + 
  ggtitle(&quot;High School Graduation Rate versus Poverty - 2019 Data&quot;)</code></pre>
<pre><code>## Warning: Removed 1876 rows containing missing values (geom_point).</code></pre>
<p><img src="regression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>It seems like fitting a linear regression to this data is reasonable. To do so, we only need a simple function in R, <code>lm</code>. Let’s fit the model and see what we get.</p>
<pre class="r"><code>mod = lm(poverty_2019 ~ hs_grad_2019, data = dat)
kable(tidy(mod)) %&gt;% kable_styling(position = &quot;center&quot;) # requires broom package</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
77.4447213
</td>
<td style="text-align:right;">
2.0066198
</td>
<td style="text-align:right;">
38.59462
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
hs_grad_2019
</td>
<td style="text-align:right;">
-0.7088124
</td>
<td style="text-align:right;">
0.0228897
</td>
<td style="text-align:right;">
-30.96645
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>How can we write down this model? What is the interpretation?</p>
<p>Next, we will discuss where these estimates come from.</p>
</div>
<div id="estimation-details" class="section level4">
<h4>Estimation Details</h4>
<p>Let’s briefly discuss <a href="https://tutorial.math.lamar.edu/classes/calci/optimization.aspx">optimization</a>. Suppose we have the function</p>
<p><span class="math display">\[\begin{equation}
f(x) = -x^2.
\end{equation}\]</span></p>
<p>and we want to know the value of <span class="math inline">\(x\)</span> that maximizes this function. How would we do this?</p>
<p>The estimation problem in linear regression is no different. Let’s consider the simple linear regression model</p>
<p><span class="math display">\[\begin{equation}
y_i = \beta x_i + \epsilon_i.
\end{equation}\]</span></p>
<p>Our estimate of <span class="math inline">\(\beta\)</span>, which we will call <span class="math inline">\(\hat{\beta}\)</span>, will be the value of <span class="math inline">\(\beta\)</span> that minimizes the sum of squared differences between the observed and the predicted values. That is, it is the <span class="math inline">\(\beta\)</span> that minimizes this function:</p>
<p><span class="math display">\[\begin{align}
f(\beta) &amp;= \sum_i (y_i - \hat{y}_i)^2 \\
&amp;= \sum_i (y_i - \beta x_i)^2 
\end{align}\]</span></p>
<p>What is this value?</p>
</div>
<div id="exercises-1" class="section level4">
<h4>Exercises 1</h4>
<ol style="list-style-type: decimal">
<li>Among counties with greater than 95% high school graduates, which county has the highest unemployment rate?</li>
<li>Using the command <code>data()</code>, find a dataset that interests you, generate a hypothesis regarding a linear association between two variables, and assess the hypothesis by first visualizing (using a scatterplot) and then fitting a linear regression model.</li>
<li>(Optional) Repeat the optimization analysis above for the model <span class="math inline">\(y_i = \beta_0 + \beta_1x_i\)</span>, taking partial derivatives and solving.</li>
</ol>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
